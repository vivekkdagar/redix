import time
import threading

# The Lock ensures that only one thread can modify the store at a time,
# preventing data corruption (race conditions) when multiple clients run SET simultaneously.
DATA_LOCK = threading.Lock()

BLOCKING_CLIENTS_LOCK = threading.Lock()
BLOCKING_STREAMS_LOCK = threading.Lock()

BLOCKING_CLIENTS = {}
BLOCKING_STREAMS = {}

CHANNEL_SUBSCRIBERS = {}
CLIENT_SUBSCRIPTIONS = {}
CLIENT_STATE = {}

SORTED_SETS = {}

STREAMS = {}

multi_flag = False

# New state for WAIT command on master
WAIT_LOCK = threading.Lock()
WAIT_CONDITION = threading.Condition(WAIT_LOCK)
# Maps replica socket to its last acknowledged offset (int)
REPLICA_ACK_OFFSETS = {}

# The central storage. Keys map to a dictionary containing value, type, and expiry metadata.
# Example: {'mykey': {'type': 'string', 'value': 'myvalue', 'expiry': 1731671220000}}
DATA_STORE = {}


def get_data_entry(key: str) -> dict | None:
    """
    Retrieves a key, checks for expiration, and performs lazy deletion if expired.
    Returns the valid data entry dictionary or None if the key is missing/expired.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)

        if data_entry is None:
            # Key does not exist
            return None

        expiry = data_entry.get("expiry")
        current_time_ms = int(time.time() * 1000)

        # Check for expiration
        if expiry is not None and current_time_ms >= expiry:
            # Key has expired; delete it
            del DATA_STORE[key]
            return None

        return data_entry


def set_string(key: str, value: str, expiry_timestamp: int | None):
    """
    Sets a key to a string value with optional expiration.
    """
    with DATA_LOCK:
        DATA_STORE[key] = {
            "type": "string",
            "value": value,
            "expiry": expiry_timestamp
        }


def set_list(key: str, elements: list[str], expiry_timestamp: int | None):
    """
    Sets a key to a list of strings with optional expiration.
    """
    with DATA_LOCK:
        DATA_STORE[key] = {
            "type": "list",
            "value": elements,
            "expiry": expiry_timestamp
        }


def existing_list(key: str) -> bool:
    """
    Checks if a list exists by key, without retrieving it.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)
        if data_entry is None:
            return False
        return data_entry.get("type") == "list"


def append_to_list(key: str, element: str):
    """
    Appends an element to an existing list at the given key.
    Assumes the list already exists.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)
        if data_entry and data_entry.get("type") == "list":
            data_entry["value"].append(element)


def size_of_list(key: str) -> int:
    """
    Returns the size of the list stored at key, or 0 if the key does not exist or is not a list.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)
        if data_entry and data_entry.get("type") == "list":
            return len(data_entry["value"])
        return 0


def lrange_rtn(key: str, start: int, end: int) -> list[str]:
    """
    Returns a sublist from the list stored at key, from start to end indices (inclusive).
    If the key does not exist or is not a list, returns an empty list.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)
        if data_entry and data_entry.get("type") == "list":
            list = data_entry["value"]
            if start < 0:
                start = start + len(list)
            if end < 0:
                end = end + len(list)
            if start > end or start >= len(list):
                return []
            if end >= len(list):
                return list[start:]

            start = max(0, start)
            return list[start:end + 1]
        return []


def prepend_to_list(key: str, element: str):
    """
    Prepends an element to an existing list at the given key.
    Assumes the list already exists.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)
        if data_entry and data_entry.get("type") == "list":
            data_entry["value"].insert(0, element)


def remove_elements_from_list(key: str, count: int) -> list[str] | None:
    """
    Removes and returns the first elements from the list at the given key.
    Returns None if the list is empty or the key does not exist/is not a list.
    """
    with DATA_LOCK:
        data_entry = DATA_STORE.get(key)
        if data_entry and data_entry.get("type") == "list":
            if data_entry["value"]:
                return [data_entry["value"].pop(0) for _ in range(count)]

            if not data_entry["value"]:
                del DATA_STORE[key]
                return None

    return None


def cleanup_blocked_client(client):
    with BLOCKING_CLIENTS_LOCK:
        for key, waiters in list(BLOCKING_CLIENTS.items()):
            BLOCKING_CLIENTS[key] = [
                cond for cond in waiters if getattr(cond, "client_socket", None) != client
            ]
            if not BLOCKING_CLIENTS[key]:
                del BLOCKING_CLIENTS[key]


def read_string(f):
    length_or_encoding_byte = read_length(f)

    # Check if the length is actually an encoding byte (prefix 0b11)
    if (length_or_encoding_byte >> 6) == 0b11:
        # It's an encoded string (C0-C3), delegate to read_encoded_string
        return read_encoded_string(f, length_or_encoding_byte)  # <<< Pass the encoding byte

    # Regular string: the result is the length
    length = length_or_encoding_byte
    data = f.read(length)
    try:
        return data.decode("utf-8")
    except UnicodeDecodeError:
        return data  # Return raw bytes if not valid UTF-8


def read_length(f):
    first_byte = f.read(1)[0]
    prefix = first_byte >> 6  # first 2 bits

    if prefix == 0b00:
        # small length
        return first_byte & 0x3F
    elif prefix == 0b01:
        # 14-bit length
        second_byte = f.read(1)[0]
        return ((first_byte & 0x3F) << 8) | second_byte
    elif prefix == 0b10:
        # 32-bit length
        return int.from_bytes(f.read(4), "big")
    else:
        # special string encoding (C0â€“C3)
        return first_byte


def read_value(f, value_type):
    if value_type == b'\x00':  # string
        return read_string(f)
    # other types like lists/hashes could be added later
    return None


def read_expiry(f, type_byte):
    if type_byte == b'\xFC':  # ms
        return int.from_bytes(f.read(8), "little")
    elif type_byte == b'\xFD':  # sec
        return int.from_bytes(f.read(4), "little")


def read_encoded_string(f, first_byte):
    encoding_type = first_byte & 0x3F  # last 6 bits
    if encoding_type == 0x00:  # C0 = 8-bit int
        val = int.from_bytes(f.read(1), "big")
        return str(val)
    elif encoding_type == 0x01:  # C1 = 16-bit int
        val = int.from_bytes(f.read(2), "little")
        return str(val)
    elif encoding_type == 0x02:  # C2 = 32-bit int
        val = int.from_bytes(f.read(4), "little")
        return str(val)
    elif encoding_type == 0x03:  # C3 = LZF compressed
        raise Exception("C3 LZF compression not supported in this stage")
    else:
        raise Exception(f"Unknown string encoding: {hex(first_byte)}")


def load_rdb_to_datastore(rdb_path):
    datastore = {}

    with open(rdb_path, "rb") as f:
        # 1. Read header (magic + 4-byte version). Do not consume the rest of the file.
        magic = f.read(5)
        if magic != b"REDIS":
            raise Exception("Unsupported RDB file: missing 'REDIS' magic")
        version = f.read(4)
        if not version or len(version) < 4:
            raise Exception("Unsupported RDB version")
        # optionally consume a single newline after the version
        maybe_nl = f.read(1)
        if maybe_nl not in (b"\n", b"\r", b""):
            f.seek(-1, 1)

        # 2. Skip metadata sections (0xFA ...)
        while True:
            byte = f.read(1)
            if not byte:
                break
            if byte == b'\xFA':
                # read metadata key and value (string encoded)
                _ = read_string(f)
                _ = read_string(f)
                continue
            # not a metadata marker, rewind one byte and continue to DB parsing
            f.seek(-1, 1)
            break

        # 3. Read database sections
        while True:
            byte = f.read(1)
            if not byte:
                break  # End of file
            if byte == b'\xFE':  # Database section
                db_index = read_length(f)

                # Hash table size info (optional)
                hash_size_marker = f.read(1)
                if hash_size_marker == b'\xFB':
                    read_length(f)  # key-value hash table size
                    read_length(f)  # expiry hash table size
                else:
                    f.seek(-1, 1)

                # Key-value pairs
                while True:
                    expiry = None
                    type_byte = f.read(1)
                    if not type_byte or type_byte == b'\xFF':
                        break
                    if type_byte in (b'\xFC', b'\xFD'):
                        expiry = read_expiry(f, type_byte)
                        type_byte = f.read(1)
                    value_type = type_byte
                    key = read_string(f)
                    value = read_value(f, value_type)
                    if value_type == b'\x00':
                        datastore[key] = {
                            "type": "string",
                            "value": value,
                            "expiry": expiry
                        }
            elif byte == b'\xFF':  # End of file section
                # After 0xFF, 8 bytes of checksum follow. Consume them.
                _ = f.read(8)
                # Ignore any extra bytes after checksum (be robust)
                break
            elif byte == b'\xFA':
                # Metadata section (shouldn't appear here, but skip if present)
                _ = read_string(f)
                _ = read_string(f)
            else:
                # Ignore any unknown/extra bytes after checksum
                break

    return datastore


def subscribe(client, channel):
    with BLOCKING_CLIENTS_LOCK:
        if channel not in CHANNEL_SUBSCRIBERS:
            CHANNEL_SUBSCRIBERS[channel] = set()
        CHANNEL_SUBSCRIBERS[channel].add(client)

        if client not in CLIENT_SUBSCRIPTIONS:
            CLIENT_SUBSCRIPTIONS[client] = set()
        CLIENT_SUBSCRIPTIONS[client].add(channel)

        if client not in CLIENT_STATE:
            CLIENT_STATE[client] = {}
        CLIENT_STATE[client]["is_subscribed"] = True


def num_client_subscriptions(client) -> int:
    """
    Returns the number of channels the given client is subscribed to.
    """
    count = 0
    with BLOCKING_CLIENTS_LOCK:
        if client in CLIENT_SUBSCRIPTIONS:
            count = len(CLIENT_SUBSCRIPTIONS[client])
    return count


def is_client_subscribed(client) -> bool:
    """
    Returns whether the given client is subscribed to any channels.
    """
    with BLOCKING_CLIENTS_LOCK:
        state = CLIENT_STATE.get(client, {})
        return state.get("is_subscribed", False)


def unsubscribe(client, channel):
    with BLOCKING_CLIENTS_LOCK:
        if channel in CHANNEL_SUBSCRIBERS:
            CHANNEL_SUBSCRIBERS[channel].discard(client)
            if not CHANNEL_SUBSCRIBERS[channel]:
                del CHANNEL_SUBSCRIBERS[channel]

        if client in CLIENT_SUBSCRIPTIONS:
            CLIENT_SUBSCRIPTIONS[client].discard(channel)
            if not CLIENT_SUBSCRIPTIONS[client]:
                del CLIENT_SUBSCRIPTIONS[client]

        if client in CLIENT_STATE:
            subscriptions = CLIENT_SUBSCRIPTIONS.get(client, set())
            CLIENT_STATE[client]["is_subscribed"] = len(subscriptions) > 0


def add_to_sorted_set(key: str, member: str, score_str: str) -> int:
    """
    Adds a member with a given score to a sorted set.
    Returns 1 if a new member was added, or 0 if an existing member's score was updated.
    """
    with DATA_LOCK:
        try:
            # Convert the score to a 64-bit float
            score = float(score_str)
        except ValueError:
            return 0

            # 1. Ensure the sorted set exists in the map
        if key not in SORTED_SETS:
            # Create a new sorted set (dictionary of members to scores)
            SORTED_SETS[key] = {}

        if key not in DATA_STORE:
            DATA_STORE[key] = {
                "type": "sorted_set",
                "value": SORTED_SETS[key],
                "expiry": None
            }

        # 2. Check if the member already exists
        is_new_member = member not in SORTED_SETS[key]

        SORTED_SETS[key][member] = score

        return 1 if is_new_member else 0


def num_sorted_set_members(key: str) -> int:
    """
    Returns the number of elements (cardinality) in the sorted set stored at key.
    """
    with DATA_LOCK:
        # Returns the size of the inner dictionary, or 0 if the key is missing
        return len(SORTED_SETS.get(key, {}))


def get_sorted_set_rank(key: str, member: str) -> int | None:
    """
    Returns the rank (0-based index) of the member in the sorted set stored at key.
    If the member does not exist, returns None.
    """
    with DATA_LOCK:
        if key not in SORTED_SETS or member not in SORTED_SETS[key]:
            return None

        # Get all members and their scores
        members_with_scores = SORTED_SETS[key].items()

        # Sort members by score (ascending), then by member name (lexicographically)
        sorted_members = sorted(members_with_scores, key=lambda item: (item[1], item[0]))

        # Find the rank of the specified member
        for rank, (m, _) in enumerate(sorted_members):
            if m == member:
                return rank

        return None  # Should not reach here due to earlier checks


def get_sorted_set_range(key: str, start: int, end: int) -> list[str]:
    """
    Returns a list of members in the sorted set stored at key, from start to end indices (inclusive).
    If the key does not exist, returns an empty list.
    """
    with DATA_LOCK:
        if key not in SORTED_SETS:
            return []

        # Get all members and their scores
        members_with_scores = SORTED_SETS[key].items()

        # Sort members by score (ascending), then by member name (lexicographically)
        sorted_members = sorted(members_with_scores, key=lambda item: (item[1], item[0]))

        # Extract just the member names
        sorted_member_names = [member for member, _ in sorted_members]

        # Handle negative indices
        if start < 0:
            start = start + len(sorted_member_names)
        if end < 0:
            end = end + len(sorted_member_names)

        # Adjust indices to be within bounds
        start = max(0, start)
        end = min(end, len(sorted_member_names) - 1)

        if start > end or start >= len(sorted_member_names):
            return []

        return sorted_member_names[start:end + 1]


def get_zscore(key: str, member: str) -> float | None:
    """
    Returns the score of the member in the sorted set stored at key.
    If the member does not exist, returns None.
    """
    with DATA_LOCK:
        if key not in SORTED_SETS or member not in SORTED_SETS[key]:
            return None

        return SORTED_SETS[key][member]


def remove_from_sorted_set(key: str, member: str) -> int:
    """
    Removes a member from the sorted set stored at key.
    Returns 1 if the member was removed, or 0 if the member did not exist.
    """
    with DATA_LOCK:
        if key not in SORTED_SETS or member not in SORTED_SETS[key]:
            return 0

        del SORTED_SETS[key][member]
        if not SORTED_SETS[key]:
            del SORTED_SETS[key]
            if key in DATA_STORE:
                del DATA_STORE[key]
        return 1


def _verify_and_parse_new_id(new_id_str: str, last_id_str: str | None) -> tuple[str | None, bytes | None]:
    """
    Parses and validates the new ID against the last ID in the stream, 
    auto-generating the sequence number if 'ms-*' is present.
    Returns: (final_valid_id_str, error_bytes). 
    """

    # Determine the ID of the last entry
    if last_id_str is None:
        last_ms, last_seq = 0, 0  # Conceptual ID for empty stream
    else:
        try:
            last_parts = last_id_str.split('-')
            last_ms = int(last_parts[0])
            last_seq = int(last_parts[1])
        except ValueError:
            return None, b"-ERR Internal error reading last stream ID\r\n"

    # 1. Handle Auto-generation of Sequence Number (ms-*)
    if new_id_str.endswith('-*'):
        try:
            new_ms = int(new_id_str.split('-')[0])
        except ValueError:
            return None, b"-ERR Invalid stream ID format\r\n"

        # Rule: millisecondsTime must be strictly greater than or equal to last
        if new_ms < last_ms:
            return None, b"-ERR The ID specified in XADD is equal or smaller than the target stream top item\r\n"

        # Determine the new sequence number
        if new_ms > last_ms:
            # New time part is greater: sequence number starts at 0, 
            # except if the time part is 0, then it starts at 1.
            new_seq = 1 if new_ms == 0 else 0
        else:  # new_ms == last_ms
            # Same time part: sequence number is last_seq + 1
            new_seq = last_seq + 1

        final_id_str = f"{new_ms}-{new_seq}"
        return final_id_str, None

    # 2. Handle Auto-generation of Full ID (*)
    if new_id_str == "*":
        # Auto-generate both millisecondsTime and sequenceNumber
        current_time_ms = int(time.time() * 1000)

        new_ms = current_time_ms
        if new_ms > last_ms:
            new_seq = 0
        else:  # new_ms == last_ms
            new_seq = last_seq + 1

        final_id_str = f"{new_ms}-{new_seq}"
        return final_id_str, None

    # 3. Handle Explicit ID (ms-seq)
    try:
        new_parts = new_id_str.split('-')
        if len(new_parts) != 2:
            return None, b"-ERR Invalid stream ID format\r\n"

        new_ms = int(new_parts[0])
        new_seq = int(new_parts[1])
    except ValueError:
        return None, b"-ERR Invalid stream ID format\r\n"

    # Rule: 0-0 is always invalid (min valid ID is 0-1)
    if new_id_str == "0-0":
        return None, b"-ERR The ID specified in XADD must be greater than 0-0\r\n"

    # Rule: ID must be strictly greater than the last ID
    # a) millisecondsTime must be strictly greater than or equal to last
    if new_ms < last_ms:
        return None, b"-ERR The ID specified in XADD is equal or smaller than the target stream top item\r\n"

    # b) If millisecondsTime are equal, sequenceNumber must be strictly greater
    if new_ms == last_ms:
        if new_seq <= last_seq:
            return None, b"-ERR The ID specified in XADD is equal or smaller than the target stream top item\r\n"

    # Validation succeeded for explicit ID
    return new_id_str, None


def xadd(key: str, id: str, fields: dict[str, str]) -> bytes:
    """
    Adds an entry to a stream at the given key with the specified ID and fields.
    Returns the ID string on success, or a RESP Error bytes on failure.
    """
    with DATA_LOCK:

        # Get last ID (safely handle non-existent key after expiration check)
        last_id_str = None
        if key in STREAMS and STREAMS[key]:
            last_id_str = STREAMS[key][-1]["id"]

        # validation
        final_id_str, error_response = _verify_and_parse_new_id(id, last_id_str)
        print(f"final_id_str: {final_id_str}")

        if error_response is not None:
            return error_response

        new_entry_id = final_id_str
        # Initialization (idempotent)
        if key not in STREAMS:
            STREAMS[key] = []
        if key not in DATA_STORE:
            DATA_STORE[key] = {
                "type": "stream",
                "value": None,  # Stream data is in STREAMS, not here
                "expiry": None
            }

        # Add Entry
        entry = {
            "id": new_entry_id,
            "fields": fields
        }
        STREAMS[key].append(entry)

        # Success: Return the ID string for command execution to format
        return new_entry_id.encode()


def xrange(key: str, start_id: str, end_id: str) -> list[dict]:
    """
    Returns a list of stream entries in the range [start_id, end_id] for the given key.
    Each entry is a dictionary with 'id' and 'fields'.
    If the key does not exist, returns an empty list.
    """
    with DATA_LOCK:
        if key not in STREAMS:
            return []

        entries = STREAMS[key]
        result = []

        for entry in entries:
            entry_id = entry["id"]
            if (start_id == "-" or compare_stream_ids(entry_id, start_id) >= 0) and \
                    (end_id == "+" or compare_stream_ids(entry_id, end_id) <= 0):
                result.append(entry)

        return result


def compare_stream_ids(id1: str, id2: str) -> int:
    """
    Compares two stream IDs.
    Returns:
        -1 if id1 < id2
         0 if id1 == id2
         1 if id1 > id2
    """
    ms1, seq1 = map(int, id1.split('-'))
    ms2, seq2 = map(int, id2.split('-'))

    if ms1 < ms2:
        return -1
    elif ms1 > ms2:
        return 1
    else:
        if seq1 < seq2:
            return -1
        elif seq1 > seq2:
            return 1
        else:
            return 0


def xread(keys: list[str], last_ids: list[str]) -> dict[str, list[dict]]:
    """
    Reads entries from multiple streams starting after the given last IDs.
    Returns a dictionary mapping each key to a list of new entries.
    If a key does not exist, it will not be included in the result.
    """
    with DATA_LOCK:
        result = {}

        for key, last_id in zip(keys, last_ids):

            if last_id == "$":
                resolved_id = get_stream_max_id(key)
            else:
                resolved_id = last_id

            if key not in STREAMS:
                continue

            entries = STREAMS[key]
            new_entries = []

            for entry in entries:
                entry_id = entry["id"]
                if compare_stream_ids(entry_id, resolved_id) > 0:
                    new_entries.append(entry)

            if new_entries:
                result[key] = new_entries

        return result


def get_stream_max_id(key: str) -> str:
    """
    Returns the ID of the last entry in the stream.
    Used for '$' in XREAD to mean "read from the end".
    Returns "0-0" if the stream is empty/non-existent, which is the conceptual ID 
    just before the first valid entry (0-1) or any other entry.
    """
    with DATA_LOCK:
        # Check if the stream key exists and has entries
        if key in STREAMS and STREAMS[key]:
            return STREAMS[key][-1]["id"]

        # If stream is empty, we return "0-0" so that the first valid entry (0-1, 1-0, etc.) 
        # is correctly recognized as greater than the starting ID.
        return "0-0"


def increment_key_value(key: str) -> tuple[int | None, str | None]:
    """
    Atomically increments the integer value of a key by one.
    Handles non-existent key, wrong type, and non-integer value errors.
    Returns: (new_value: int | None, error_message: str | None)
    """
    data_entry = get_data_entry(key)  # This already checks for expiry
    with DATA_LOCK:

        print("retrieved data")
        # 1. Key does not exist: Initialize to 0, then increment to 1.
        if data_entry is None:
            # We must set the key to "1" directly, not "0" then "1"
            DATA_STORE[key] = {
                "type": "string",
                "value": "1",
                "expiry": None
            }
            return 1, None

        # 2. Key exists but is the wrong type
        if data_entry.get("type") != "string":
            return None, "-WRONGTYPE Operation against a key holding the wrong kind of value\r\n"

        current_value_str = data_entry["value"]

        # 3. Key exists and is a string, but not a valid integer
        try:
            current_value = int(current_value_str)
        except ValueError:
            return None, "-ERR value is not an integer or out of range\r\n"

        # 4. Perform increment and check for overflow (Redis uses signed 64-bit integers)
        # Note: Python integers don't overflow, so we must check explicitly.
        # Max signed 64-bit integer: 2^63 - 1
        MAX_64_BIT = 9223372036854775807
        MIN_64_BIT = -9223372036854775808

        if current_value >= MAX_64_BIT or current_value < MIN_64_BIT:
            # An increment will definitely cause an overflow from MAX_64_BIT,
            # and we should prevent modification if the value is already at a limit
            return None, "-ERR increment or decrement would overflow\r\n"

        # Redis behavior: INCR stops at MAX_64_BIT, meaning you can't INCR 9223372036854775807
        if current_value == MAX_64_BIT:
            return None, "-ERR increment or decrement would overflow\r\n"

        new_value = current_value + 1

        # 5. Update and return
        data_entry["value"] = str(new_value)
        return new_value, None


def is_client_in_multi(client) -> bool:
    """
    Returns whether the given client has an active transaction (is in MULTI mode).
    """
    # Note: Assumes CLIENT_STATE access is guarded by BLOCKING_CLIENTS_LOCK 
    # since it's used for subscription state. Reusing that lock here for consistency.
    with BLOCKING_CLIENTS_LOCK:
        state = CLIENT_STATE.get(client, {})
        return state.get("is_in_multi", False)


def set_client_in_multi(client, state: bool):
    """
    Sets the client's transaction state (True for MULTI, False otherwise).
    """
    with BLOCKING_CLIENTS_LOCK:
        if client not in CLIENT_STATE:
            CLIENT_STATE[client] = {}
        CLIENT_STATE[client]["is_in_multi"] = state

        # Initialize or clear the command queue when setting the state
        if state:
            # Start of transaction: initialize empty queue
            CLIENT_STATE[client]["queue"] = []
        else:
            # End of transaction (EXEC/DISCARD): clear the queue
            CLIENT_STATE[client]["queue"] = []


def get_client_queued_commands(client) -> list:
    """
    Returns the list of commands queued for the client.
    """
    with BLOCKING_CLIENTS_LOCK:
        return CLIENT_STATE.get(client, {}).get("queue", [])


def enqueue_client_command(client, command: str, arguments: list):
    """
    Adds a command and its arguments to the client's transaction queue.
    Assumes client is already in a MULTI state.
    """
    with BLOCKING_CLIENTS_LOCK:
        state = CLIENT_STATE.get(client, {})
        # Ensure the queue exists (it should, after MULTI)
        if "queue" not in state:
            state["queue"] = []

        # Store the command as a tuple: (COMMAND, [arg1, arg2, ...])
        state["queue"].append((command, arguments))


def _serialize_command_to_resp_array(command: str, arguments: list) -> bytes:
    """
    Converts a command and its arguments into a raw RESP array byte string.
    Example: ('SET', ['foo', 'bar']) -> b'*3\r\n$3\r\nSET\r\n$3\r\nfoo\r\n$3\r\nbar\r\n'
    """
    elements = [command] + arguments

    # Start with the array header: *<count>\r\n
    resp_array_parts = [b"*" + str(len(elements)).encode() + b"\r\n"]

    for element in elements:
        # Each element is a bulk string: $<length>\r\n<content>\r\n
        element_bytes = element.encode()
        length_bytes = str(len(element_bytes)).encode()

        resp_array_parts.append(b"$" + length_bytes + b"\r\n")
        resp_array_parts.append(element_bytes + b"\r\n")

    return b"".join(resp_array_parts)