import asyncio
import time
from collections import defaultdict, deque

BUF_SIZE = 4096

# Global data stores
lst = defaultdict(list)      # For Redis lists
remove = defaultdict(deque)  # For blocked clients (key → deque of writers)
d = defaultdict(tuple)       # For key-value store with expiry
streams = defaultdict(lambda: defaultdict(list))
lastusedtime = 0
lastusedseq = defaultdict(int)
xread_zero_block = defaultdict(list)
multi_con = []
# multi_deque = deque()
multi_deques = defaultdict(deque)

# Command handler functions that return results instead of writing to client
async def handle_ping(elements):
    return b"+PONG\r\n"

async def handle_echo(elements):
    msg = elements[1]
    return b"$" + str(len(msg)).encode() + b"\r\n" + msg.encode() + b"\r\n"

async def handle_set(elements):
    key, value = elements[1], elements[2]
    expiry = float('inf')

    if len(elements) >= 5 and elements[3].upper() == 'PX':
        expiry = time.time() + int(elements[4]) / 1000

    d[key] = [int(value) if value.isdigit() else value, expiry]
    return b"+OK\r\n"

async def handle_get(elements):
    key = elements[1]
    if key in d:
        val, expiry = d[key]
        if expiry < time.time():
            del d[key]
            return b"$-1\r\n"
        else:
            x = len(str(val))
            return f"${x}\r\n{val}\r\n".encode()
    else:
        return b"$-1\r\n"

async def handle_rpush(elements):
    key = elements[1]
    for v in elements[2:]:
        lst[key].append(v)

    result = f":{len(lst[key])}\r\n".encode()

    # Wake up first blocked client (if any)
    if key in remove and remove[key]:
        blocked_writer = remove[key].popleft()
        if lst[key]:
            element = lst[key].pop(0)
            resp = (
                f"*2\r\n${len(key)}\r\n{key}\r\n"
                f"${len(element)}\r\n{element}\r\n"
            ).encode()
            # This side effect needs to be handled separately
            asyncio.create_task(send_to_writer(blocked_writer, resp))

    return result

async def handle_lpush(elements):
    key = elements[1]
    for v in elements[2:]:
        lst[key].insert(0, v)
    return f":{len(lst[key])}\r\n".encode()

async def handle_llen(elements):
    key = elements[1]
    return f":{len(lst[key])}\r\n".encode()

async def handle_lrange(elements):
    key = elements[1]
    start = int(elements[2])
    end = int(elements[3])
    arr = lst[key]
    n = len(arr)

    if start < 0:
        start += n
    if end < 0:
        end += n
    start = max(0, start)
    end = min(end, n - 1)
    if start > end or n == 0:
        return b"*0\r\n"
    else:
        subset = arr[start:end + 1]
        resp = f"*{len(subset)}\r\n".encode()
        for item in subset:
            resp += f"${len(item)}\r\n{item}\r\n".encode()
        return resp

async def handle_lpop(elements):
    key = elements[1]
    if len(elements) == 2:
        if lst[key]:
            element = lst[key].pop(0)
            return f"${len(element)}\r\n{element}\r\n".encode()
        else:
            return b"$-1\r\n"
    else:
        count = int(elements[2])
        popped = [lst[key].pop(0) for _ in range(min(count, len(lst[key])))]
        if popped:
            resp = f"*{len(popped)}\r\n".encode()
            for item in popped:
                resp += f"${len(item)}\r\n{item}\r\n".encode()
            return resp
        else:
            return b"*0\r\n"

async def handle_blpop(elements, writer):
    key = elements[1]
    timeout = float(elements[2])

    # If the list has items, return immediately
    if lst[key]:
        element = lst[key].pop(0)
        return (
            f"*2\r\n${len(key)}\r\n{key}\r\n"
            f"${len(element)}\r\n{element}\r\n"
        ).encode()
    else:
        # No elements → block
        remove[key].append(writer)

        async def unblock_after_timeout():
            if timeout != 0:
                await asyncio.sleep(timeout)
                # Still blocked? Unblock with nil
                if writer in remove[key]:
                    remove[key].remove(writer)
                    await send_to_writer(writer, b"*-1\r\n")

        asyncio.create_task(unblock_after_timeout())
        return None  # No immediate response

async def handle_type(elements):
    key = elements[1]
    if key in streams:
        return b"+stream\r\n"
    elif key in d and d[key][1] >= time.time():
        val = d[key][0]
        if isinstance(val, str):
            typename = "string"
        elif isinstance(val, list):
            typename = "list"
        else:
            typename = "none"
        return f"+{typename}\r\n".encode()
    else:
        return b"+none\r\n"

async def handle_xadd(elements, writer):
    global lastusedtime
    stream_key = elements[1]
    entry_id = elements[2]

    # Parse or generate entry ID
    if entry_id == '*':
        # Fully auto-generated ID
        t = time.time_ns() // 1000000
        if t in lastusedseq:
            sequence = lastusedseq[t] + 1
        elif t == 0:
            sequence = 1
        else:
            sequence = 0
        final_id = f"{t}-{sequence}"
    elif '-' in entry_id:
        t_str, seq_str = entry_id.split('-')
        if t_str == '0':
            t = 0
        else:
            t = int(t_str) if t_str != '*' else time.time_ns() // 1000000

        if seq_str == '*':
            # Partial auto-generation (timestamp provided, sequence auto)
            if t in lastusedseq:
                sequence = lastusedseq[t] + 1
            elif t == 0:
                sequence = 1
            else:
                sequence = 0
            final_id = f"{t}-{sequence}"
        else:
            # Fully specified ID
            sequence = int(seq_str)
            final_id = entry_id
    else:
        # Handle case where ID doesn't have '-'
        t = time.time_ns() // 1000000
        if t in lastusedseq:
            sequence = lastusedseq[t] + 1
        else:
            sequence = 0
        final_id = f"{t}-{sequence}"

    # Validate the ID
    if t == 0 and sequence == 0:
        return b'-ERR The ID specified in XADD must be greater than 0-0\r\n'

    if t < lastusedtime or (t == lastusedtime and sequence <= lastusedseq.get(lastusedtime, -1)):
        return b'-ERR The ID specified in XADD is equal or smaller than the target stream top item\r\n'

    # Store the entry
    lastusedtime = t
    lastusedseq[lastusedtime] = sequence
    streams[stream_key][final_id].append(elements[3:])

    # Check if any blocked XREAD clients need to be notified
    if stream_key in xread_zero_block and xread_zero_block[stream_key]:
        blocked_data = xread_zero_block[stream_key]
        if isinstance(blocked_data, list) and len(blocked_data) >= 2:
            blocked_start, blocked_writer = blocked_data

            # Send new entry to blocked client
            entries = ""
            cnt = 0
            for k, v_list in streams[stream_key].items():
                if k > blocked_start:  # only entries newer than given ID
                    cnt += 1
                    field_values = ""
                    for fields in v_list:
                        field_values += f"*{len(fields)}\r\n"
                        for field in fields:
                            field_values += f"${len(field)}\r\n{field}\r\n"
                    entries += f"*2\r\n${len(k)}\r\n{k}\r\n{field_values}"

            if cnt > 0:
                ans = f"*1\r\n*2\r\n${len(stream_key)}\r\n{stream_key}\r\n*{cnt}\r\n{entries}"
                asyncio.create_task(send_to_writer(blocked_writer, ans.encode()))

            # Remove from blocked list
            xread_zero_block[stream_key] = []

    # Return as BULK STRING ($) not SIMPLE STRING (+)
    return f"${len(final_id)}\r\n{final_id}\r\n".encode()

async def handle_xrange(elements):
    if len(elements) == 4 and elements[3] == '+':
        key = elements[1]
        start = elements[2]
        ans = ''
        cnt = 0
        for k, v in streams[key].items():
            if start <= k:
                ans += "*2\r\n"
                ans += '$' + str(len(k)) + "\r\n" + k + "\r\n"
                cnt += 1
                ans += '*' + str(len(v) * 2) + '\r\n'
                for a, b in v:
                    ans += '$' + str(len(a)) + '\r\n' + a + '\r\n'
                    ans += '$' + str(len(b)) + '\r\n' + b + '\r\n'
        return ('*' + str(cnt) + '\r\n' + ans).encode()
    else:
        start, end = elements[2], elements[3]
        key = elements[1]
        ans = ''
        cnt = 0
        for k, v in streams[key].items():
            if start <= k <= end:
                ans += "*2\r\n"
                ans += '$' + str(len(k)) + "\r\n" + k + "\r\n"
                cnt += 1
                ans += '*' + str(len(v) * 2) + '\r\n'
                for a, b in v:
                    ans += '$' + str(len(a)) + '\r\n' + a + '\r\n'
                    ans += '$' + str(len(b)) + '\r\n' + b + '\r\n'
        return ('*' + str(cnt) + '\r\n' + ans).encode()

async def handle_xread(elements, writer):
    if elements[1].lower() == 'block':
        timeout_ms = int(elements[2])
        key = elements[4]
        start = elements[5]

        # Convert $ to current max ID
        if start == '$':
            if key in streams and streams[key]:
                start_id = max(streams[key].keys())
            else:
                start_id = '0-0'
        else:
            start_id = start

        # Check if entries already exist that are newer than start
        new_entries = []
        if key in streams and streams[key]:
            for entry_id, fields_list in streams[key].items():
                if entry_id > start_id:
                    new_entries.append((entry_id, fields_list))

        # If entries are available NOW, return them immediately
        if new_entries:
            # Format and send the response immediately
            entries = ""
            cnt = 0
            for k, v_list in new_entries:
                cnt += 1
                field_values = ""
                for fields in v_list:
                    field_values += f"*{len(fields)}\r\n"
                    for field in fields:
                        field_values += f"${len(field)}\r\n{field}\r\n"
                entries += f"*2\r\n${len(k)}\r\n{k}\r\n{field_values}"

            return f"*1\r\n*2\r\n${len(key)}\r\n{key}\r\n*{cnt}\r\n{entries}".encode()

        # Only wait if no entries are available
        if timeout_ms == 0:
            xread_zero_block[key] = [start_id, writer]
            return None  # No immediate response

        # For non-zero timeout, wait and then respond
        async def unblock_after_timeout():
            await asyncio.sleep(timeout_ms / 1000)

            # Check for new entries again after timeout
            final_entries = []
            if key in streams and streams[key]:
                for entry_id, fields_list in streams[key].items():
                    if entry_id > start_id:
                        final_entries.append((entry_id, fields_list))

            if final_entries:
                # Format the response
                entries = ""
                cnt = 0
                for k, v_list in final_entries:
                    cnt += 1
                    field_values = ""
                    for fields in v_list:
                        field_values += f"*{len(fields)}\r\n"
                        for field in fields:
                            field_values += f"${len(field)}\r\n{field}\r\n"
                    entries += f"*2\r\n${len(k)}\r\n{k}\r\n{field_values}"

                response = f"*1\r\n*2\r\n${len(key)}\r\n{key}\r\n*{cnt}\r\n{entries}"
            else:
                response = "*-1\r\n"  # Null response

            await send_to_writer(writer, response.encode())

        asyncio.create_task(unblock_after_timeout())
        return None  # No immediate response

    else:
        # Non-blocking XREAD
        total = len(elements[2:])
        half = total // 2
        keys = elements[2:2 + half]
        starts = elements[2 + half:]
        ans = f"*{len(keys)}\r\n"  # Top-level array contains all streams

        for idx, key in enumerate(keys):
            start = starts[idx]
            entries = ""
            cnt = 0

            if key in streams:
                for k, v_list in streams[key].items():
                    if start < k:
                        cnt += 1
                        # Flatten all field-value pairs for this entry
                        field_values = ""
                        for fields in v_list:
                            field_values += f"*{len(fields)}\r\n"
                            for field in fields:
                                field_values += f"${len(field)}\r\n{field}\r\n"
                        entries += f"*2\r\n${len(k)}\r\n{k}\r\n{field_values}"

            ans += f"*2\r\n${len(key)}\r\n{key}\r\n*{cnt}\r\n{entries}"

        return ans.encode()

async def handle_incr(elements):
    key, value = elements[1], 1

    if key in d:
        if isinstance(d[key][0], int):
            d[key][0] += 1
            return b":" + str(d[key][0]).encode() + b"\r\n"
        else:
            return b"-ERR value is not an integer or out of range\r\n"
    else:
        expiry = float('inf')

        if len(elements) >= 5 and elements[3].upper() == 'PX':
            expiry = time.time() + int(elements[4]) / 1000

        d[key] = [value, expiry]
        return b":1\r\n"

async def handle_multi(writer):
    multi_con.append(writer)
    # multi_deques[str(writer)]
    return b"+OK\r\n"
async def handle_discard(writer):
    if writer in multi_con:
        multi_con.remove(writer)
        multi_deques[str(writer)].clear()
        return b'+OK\r\n'
    else:
        return b'-ERR DISCARD without MULTI\r\n'


async def handle_exec(writer):
    if writer not in multi_con:
        return b'-ERR EXEC without MULTI\r\n'
    else:
        multi_con.remove(writer)
        if not multi_deques[str(writer)]:
            return b'*0\r\n'
        else:
            results = []
            for queued_elements in multi_deques[str(writer)]:
                result = await execute_command(queued_elements, writer)
                if result is not None:  # Only include commands that have immediate responses
                    results.append(result)

            # Clear the multi deque after execution
            multi_deques[str(writer)].clear()

            # Format results as RESP array
            if not results:
                return b'*0\r\n'

            resp_array = f"*{len(results)}\r\n".encode()
            for result in results:
                # Each result is already in RESP format, we need to extract the actual content
                # and format it as array elements
                result_str = result.decode()
                if result_str.startswith('+') or result_str.startswith('-'):
                    # Simple string or error
                    resp_array += result
                elif result_str.startswith(':'):
                    # Integer
                    resp_array += result
                elif result_str.startswith('$'):
                    # Bulk string
                    resp_array += result
                elif result_str.startswith('*'):
                    # Array - this needs special handling
                    resp_array += result
                else:
                    # Fallback
                    resp_array += result

            return resp_array

async def execute_command(elements, writer):
    """Execute a command and return the result (or None for async commands)"""
    cmd = elements[0].lower()

    command_handlers = {
        'ping': handle_ping,
        'echo': handle_echo,
        'set': handle_set,
        'get': handle_get,
        'rpush': handle_rpush,
        'lpush': handle_lpush,
        'llen': handle_llen,
        'lrange': handle_lrange,
        'lpop': handle_lpop,
        'blpop': lambda e: handle_blpop(e, writer),
        'type': handle_type,
        'xadd': lambda e: handle_xadd(e, writer),
        'xrange': handle_xrange,
        'xread': lambda e: handle_xread(e, writer),
        'incr': handle_incr,
        'multi': lambda e: handle_multi(writer),
        'exec': lambda e: handle_exec(writer),
        'discard': lambda e: handle_discard(writer)
    }

    if cmd in command_handlers:
        return await command_handlers[cmd](elements)
    else:
        return b"-ERR unknown command\r\n"

async def send_to_writer(writer, data):
    """Helper function to send data to writer and drain"""
    writer.write(data)
    await writer.drain()

async def handle_command(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):
    global lst, remove, d

    while True:
        chunk = await reader.read(BUF_SIZE)
        if not chunk:
            break

        i = 0
        if chunk[i] == ord('*'):
            i += 1
            j = chunk.find(b'\r\n', i)
            arrlen = int(chunk[i:j])
        i = j + 2
        elements = []
        for _ in range(arrlen):
            if chunk[i] == ord('$'):
                i += 1
                j = chunk.find(b'\r\n', i)
                wlen = int(chunk[i:j])
                i = j + 2
                element = chunk[i:i + wlen]
                i += wlen + 2
                elements.append(element.decode())

        cmd = elements[0].lower()

        # Handle MULTI transaction mode
        if cmd == 'discard':
            result = await execute_command(elements, writer)
            writer.write(result)
            result = None
        elif writer in multi_con and cmd != 'exec' and cmd != 'multi':
            multi_deques[str(writer)].append(elements)
            result = b'+QUEUED\r\n'
        else:
            result = await execute_command(elements, writer)

        # Send response if available (some commands like BLPOP may not have immediate responses)
        if result is not None:
            await send_to_writer(writer, result)

        await writer.drain()

    writer.close()
    await writer.wait_closed()

async def main():
    server = await asyncio.start_server(handle_command, "localhost", 6379)
    print("Async Redis clone running on ('localhost', 6379)")
    async with server:
        await server.serve_forever()

if __name__ == "__main__":
    asyncio.run(main())